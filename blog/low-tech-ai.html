<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
	<meta name=viewport content="width=800">
	<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
	<title>ðŸŽ  Low Tech AI</title>
	<meta name="description" content="Some trends resulting in a possible future of low-tech AI.">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="stylesheet" type="text/css" href="../blog.css">
	<!-- <link rel="stylesheet" type="text/css" href="../style.css"> -->
	<!-- <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700;900&display=swap" rel="stylesheet">
</head>

<body>
	<div class="container">
		<div class="top-row">
			<div id="ddesc">
				<h1><a href="../index.html" class="home-link">Thomas Wolf</a></h1>
				<div class="blog-nav">
					<a href="../index.html">Home</a> / 
					<a href="blog.html">Blog</a> /
					<span>ðŸŽ  Low Tech AI</span>
				</div>
			</div>
		</div>
	</div>

	<div class="container blog-post-container">
		<article class="blog-post-content">
			<header>
				<h1>ðŸŽ  Low Tech AI</h1>
			</header>

			<div class="post-body">

<p>Lately, I've been thinking a lot about something I've begun calling "low-tech AI." It's not a formal term yet, but it neatly describes several distinct trends converging in the AI landscape. These trends might initially seem unrelated, but together they suggest a future in which sophisticated artificial intelligence quietly integrates into everyday technology stacks without demanding huge upgrades or high complexity.</p>


<p><strong>First trend: Smaller Models, Increased Intelligence</strong></p>


<p>A couple years ago, improving AI meant building bigger modelsâ€”larger parameter counts, massive compute clusters, and huge energy budgets. Recently, this has shifted dramatically. Newer AI models, exemplified in the Qwen, DeepSeek, Llama, Phi series, achieve roughly the same performance as their predecessors but at half, one-tenth or even one-twentieth the size. Simultaneously, personal computing power keeps growing more affordable. A GPU today, costing a few hundred dollars, matches the power of what required several thousands just a short while ago.</p>


<p>Extrapolating along these two lines means a fixed level of intelligence gets cheaper every year, fit increasingly more affordable hardware.</p>


<p><strong>Second trend: Simplified Architecture</strong></p>


<p>The internal complexity of traditional software stacks often resembles a sprawling bureaucracy: countless branches, loops, and conditions. By contrast, inference in an AI model is remarkably straightforward. It mostly involves linear algebraâ€”vast tensor operations executed in a single sequence rather than conditionally (even for Mixture-of-experts).</p>


<p>Hardware designers have taken notice, simplifying chips drastically for these linear tasks. Companies like Cerebras, Groq, Etched, and Fractile are building specialized AI hardware stripped down to essentials, which run way more efficiently and with fewer unexpected complications than traditional CPUs.</p>


<p><strong>Third trend: Seamless Integration into Existing Systems</strong></p>


<p>One surprising benefit of language- and vision-based AI models is their inherent compatibility with legacy systems. Because these models are trained on vast collections of human-written textâ€”including code, documentation, visual interfaces and protocolsâ€”they naturally understand and integrate with familiar interfaces. Embedding AI into existing softwareâ€”and increasingly hardwareâ€”systems requires little change, lowering both friction and adoption barriers.</p>


<p>A bank running software from the early 2000s doesn't need to overhaul its entire infrastructure; instead, it might simply plug in an AI interface to its existing transaction logs or legacy software. Overnight, older system can gain capabilities previously unimaginable without disruptive upgrades.</p>


<p><strong>Imagining the Possibilities</strong></p>


<p>Imagine a small chip, drawing just five watts of power, running a model with billions of parameters that surpasses GPT-4 capabilities. Such a device could power autonomous drones, home assistants, or even local AI devices, all operating at low cost and minimal energy.</p>


<p>Alternatively, think of a small, traditional businessâ€”perhaps a manufacturing plant running software that's barely changed since the early 2000s. By adding just a small AI component to their existing stack, they might suddenly manage predictive maintenance, real-time inventory management, and complex optimizations without an expensive overhaul.</p>


<p><strong>Societal Implications</strong></p>


<p>This shift toward low-tech AI will lead to surprisingly rapid societal changes. We've already seen something analogous in how smartphones bypassed desktop computers in many regions around the world. Countries that never widely adopted wired infrastructure moved directly into mobile, leapfrogging intermediate steps. Low-tech AI could similarly allow societies or businesses to leap directly into advanced capabilities without incremental technology investments.</p>


<p>PS: This technological leap reminds me of Lois McMaster Bujold's "Vorkosigan Saga," where Barrayar's society vaults from medieval feudalism directly to interstellar technology after reconnecting with the wider galaxy. May our journey be smoother, but equally revolutionary.</p>
</div>
</div>
</article>
</div>

<div class="container">
<div id="bottom" class="row">
Copyright Thomas Wolf 2017-2025
</div>
</div>

</body>
</html>
