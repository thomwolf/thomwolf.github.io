<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
	<meta name=viewport content="width=800">
	<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
	<title>ðŸŽ  Low Tech AI</title>
	<meta name="description" content="Some trends resulting in a possible future of low-tech AI.">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="stylesheet" type="text/css" href="../blog.css">
	<!-- <link rel="stylesheet" type="text/css" href="../style.css"> -->
	<link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
	<div class="container">
		<div class="top-row">
			<div id="ddesc">
				<h1><a href="../index.html" class="home-link">Thomas Wolf</a></h1>
				<div class="blog-nav">
					<a href="../index.html">Home</a> / 
					<a href="blog.html">Blog</a> /
					<span>ðŸŽ  Low Tech AI</span>
				</div>
			</div>
		</div>
	</div>

	<div class="container blog-post-container">
		<article class="blog-post-content">
			<header>
				<h1>ðŸŽ  Low Tech AI</h1>
				<div class="post-meta">
					<time>May 14, 2025</time>
					<span class="reading-time">15 min read</span>
					<span class="category">low-tech</span>
					<span class="category">ai</span>
				</div>
			</header>

			<div class="post-body">

<p><strong>Intelligence at the intersection of simplicity and scale</strong></p>


<p>Lately, I've been thinking a lot about something I've begun calling "low-tech AI." It's not a formal term yet, but it neatly describes several distinct trends converging in the AI landscape. These trends might initially seem unrelated, but together they suggest a future in which sophisticated artificial intelligence quietly integrates into everyday technology stacks without demanding huge upgrades or high complexity.</p>


<p><strong>Trend 1: Smaller Models, Same Intelligence</strong></p>


<p>A year or two ago, improving AI meant building bigger modelsâ€”larger parameter counts, massive compute clusters, and huge energy budgets. Recently, this has shifted dramatically. Newer AI models, such as the Llama or Qwen series, achieve roughly the same performance as their predecessors but at one-tenth or even one-twentieth the size. Simultaneously, personal computing power keeps growing more affordable. A GPU today, costing a few hundred dollars, matches the power of what required tens of thousands just a short while ago.</p>


<p>This convergence means a fixed level of intelligence gets cheaper every year, shrinking down to fit increasingly modest hardware.</p>


<p><strong>Trend 2: Simplified Architecture</strong></p>


<p>The internal complexity of traditional software stacks often resembles a sprawling bureaucracy: countless branches, loops, and conditions. By contrast, AI inference is remarkably straightforward. It mostly involves linear algebraâ€”vast tensor operations executed sequentially rather than conditionally.</p>


<p>Hardware designers have taken notice, simplifying chips specifically for these linear tasks. Companies like Cerebras, Groq, Etched, and Fractile are building specialized AI hardware stripped down to essentials, which run more efficiently and with fewer unexpected complications than traditional CPUs.</p>


<p><strong>Trend 3: Seamless Integration into Existing Systems</strong></p>


<p>One surprising benefit of language-based AI models is their inherent compatibility with legacy systems. Because these models train on vast collections of human-written textâ€”including code, documentation, and protocolsâ€”they naturally understand and generate familiar interfaces. Integrating AI into existing systems thus requires little change, reducing friction and adoption barriers.</p>


<p>A bank running software from the early 2000s doesn't need to overhaul its entire infrastructure; instead, it might simply connect an AI interface to its existing transaction logs. Overnight, it gains capabilities previously unimaginable without disruptive upgrades.</p>


<p><strong>Imagining the Possibilities</strong></p>


<p>Imagine a small chip, drawing just five watts of power, running a model with billions of parameters that surpasses GPT-4 capabilities. Such a device could power autonomous drones, home assistants, or medical devices, all operating at low cost and minimal energy.</p>


<p>Alternatively, think of a small, traditional businessâ€”perhaps a manufacturing plant running software that's barely changed since the early 2000s. By adding just a small AI component to their existing stack, they might suddenly manage predictive maintenance, real-time inventory management, and complex optimizations without an expensive overhaul.</p>


<p><strong>Societal Implications</strong></p>


<p>This shift toward low-tech AI may lead to surprisingly rapid societal changes. We've already seen something analogous in how smartphones bypassed desktop computers in many regions around the world. Countries that never widely adopted wired infrastructure moved directly into mobile, leapfrogging intermediate steps. Low-tech AI could similarly allow societies or businesses to leap directly into advanced capabilities without incremental technology investments.</p>


<p>It reminds me, in a way, of Lois McMaster Bujold's "Vorkosigan Saga," where a planet jumps directly from medieval technology to spaceships upon contact with a more advanced civilization. Hopefully, our own leap will be gentlerâ€”but equally transformative.</p>
<div class="post-footer">
	<div class="tags">
		<span class="tag">low-tech</span>
		<span class="tag">ai</span>
</div>
</div>
</div>
</article>
</div>

<div class="container">
<div id="bottom" class="row">
Copyright Thomas Wolf 2017-2025
</div>
</div>

</body>
</html>
